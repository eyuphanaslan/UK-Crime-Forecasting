# UK-Crime-Forecasting
Data science project for Udacity: Analyzing and forecasting UK crime trends.

ğŸ“Œ Project Overview

This project analyses and forecasts crime trends using UK monthly crime data across multiple crime categories.
It applies time-series analysis, machine learning, and uncertainty estimation to produce interpretable, decision-ready forecasts.

The project is designed as a serious applied data science pipeline, not a toy ML example.

ğŸ¯ Objectives

Understand historical crime patterns (trend & seasonality)

Compare multiple forecasting models per crime type

Quantify uncertainty (minâ€“max / confidence ranges)

Perform rolling (walk-forward) evaluation

Forecast future crime volumes responsibly

Enable interactive exploration of model behaviour

Prepare ground for spatial and policy-level analysis

ğŸ—‚ Dataset Summary
Data Characteristics

Time span: 36 months

Frequency: Monthly

Crime types: 14 categories

Raw granularity: Incident-level data

Model input: Aggregated monthly counts per crime type

Core Columns Used
Column	Description
Month	Time index (YYYY-MM)
Crime type	Crime category
count	Monthly incident count

Spatial fields (latitude/longitude) exist but are handled in separate spatial analysis chapters.

ğŸ§  Why This Is a Time-Series Problem

Crime data violates many assumptions of standard ML:

Strong annual seasonality

Non-stationarity (policy, economy, social changes)

Structural breaks (e.g. COVID, enforcement changes)

Highly uneven variance across crime types

Therefore:

Random train/test splits are invalid

Cross-validation must respect time

Forecasts must include uncertainty

ğŸ” Backtesting vs Forecasting (Critical Concept)
Backtesting (Evaluation)

Uses last 6 months

Purpose: measure accuracy against known reality

Metrics: MAE, RMSE, RÂ²

Only possible where actual data exists

Forecasting (Projection)

Predicts next 12 months

No true accuracy metrics possible

Must include uncertainty bands

6 months is a deliberate, professional choice:

Recent enough to reflect current dynamics

Long enough for meaningful evaluation

Preserves sufficient training data

ğŸ”„ Rolling / Walk-Forward Learning

Instead of a single static model fit, the project uses:

Expanding Window Strategy

Train on months 1â€“24 â†’ test on 25â€“30

Expand to months 1â€“30 â†’ test on 31â€“36

Train on all data â†’ forecast months 37â€“48

This simulates real-world model deployment, where models improve as new data arrives.

This approach is standard in:

Finance

Energy forecasting

Epidemiology

Crime analytics

ğŸ§© Crime-by-Crime Analysis

The system enforces single-crime analysis per run:

Prevents incorrect cross-crime assumptions

Improves interpretability

Allows tailored model selection

Crime types behave very differently:

Some are stable & seasonal

Some are sparse & volatile

Some are policy-sensitive

A one-size-fits-all model is inappropriate.

ğŸ¤– Forecasting Models Used

Each model represents a different hypothesis about crime behaviour.

1ï¸âƒ£ Seasonal Naive (Baseline)

Assumption:

â€œThis month â‰ˆ same month last yearâ€

Extremely strong baseline

Used to detect over-engineering

If a model cannot beat this, it is rejected

2ï¸âƒ£ SARIMA (Statistical Time-Series)

Strengths

Native confidence intervals

Interpretable components (trend/seasonality)

Weaknesses

Sensitive to non-stationarity

Can produce explosive forecasts

Exploding forecasts are signals, not bugs.

3ï¸âƒ£ Linear Regression

Simple and interpretable

Captures trend + seasonality

Sanity check for complexity

4ï¸âƒ£ Ridge & Lasso Regression

Regularised linear models

Reduce overfitting

Lasso performs feature selection

5ï¸âƒ£ Polynomial Regression (Degree 2)

Captures smooth non-linear trends

Still interpretable

Avoids high-degree overfitting

6ï¸âƒ£ Gradient Boosting Regressor (GBR)

Machine Learning model

Handles non-linear relationships

Robust to noise

Often strongest performer

No native uncertainty â†’ estimated via residual dispersion.

ğŸ§® Feature Engineering

Time is explicitly encoded using:

Feature	Purpose
t	Global trend
sin(2Ï€t/12)	Annual seasonality
cos(2Ï€t/12)	Annual seasonality

This allows ML models to correctly learn cyclical patterns.

ğŸ“‰ Uncertainty Estimation

Point forecasts alone are misleading.

Interval Methods
Model	Interval Source
SARIMA	Native confidence intervals
ML / Regression	Â±1.96 Ã— RMSE

This approximates a 95% prediction interval.

Uncertainty bands:

Expand into the future

Reveal instability

Prevent false confidence

ğŸ“Š Interactive Visualisation

Outputs are standalone interactive HTML files:

Toggle models on/off via legend

Hover for values

Zoom and pan

Compare uncertainty ranges visually

No Python or notebook required to view.

ğŸ“ Outputs

Each run generates:

One HTML forecast per selected crime

Timestamped for traceability

Example:

forecast_Robbery_20260107_153012.html

ğŸ§ª Interpretation Guidelines

Negative RÂ² is not a bug
â†’ Model performs worse than predicting the mean

Exploding forecasts indicate instability
â†’ Often policy-driven or structurally changing crimes

Uncertainty bands matter more than point forecasts

ğŸš§ What This Project Is / Is Not
âœ… This IS:

Applied data science

Responsible forecasting

Interpretable ML

Decision-support analytics

âŒ This is NOT:

Deep learning

Reinforcement learning

Real-time prediction

Causal inference

Those require significantly more data.

ğŸš€ Future Extensions

Possible next steps:

Automatic model ranking

Ensemble forecasting

Structural break detection

Crime volatility classification

Spatialâ€“temporal fusion

Policy impact simulation

Interactive dashboards (e.g. Streamlit)

ğŸ“ Final Note

This project follows professional forecasting standards:

Correct time-aware validation

Honest uncertainty

Multiple model comparison

Interpretability over hype

It is intentionally â€œheavyâ€ because reality is heavy.

This README is intended to serve as:

Project anchor

Context reset for new AI chats

Foundation for future extensions
